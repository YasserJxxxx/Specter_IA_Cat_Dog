# üêàüêï Clasificador Binario de Perros y Gatos (Regresi√≥n Log√≠stica - Baseline)

[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-v1.0+-orange.svg)](https://scikit-learn.org/stable/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## üí° Descripci√≥n General del Proyecto

Este proyecto implementa un clasificador binario de im√°genes para la identificaci√≥n de **perros** y **gatos**. Se utiliza la **Regresi√≥n Log√≠stica** como modelo de **l√≠nea base (baseline)**. El clasificador opera sobre los p√≠xeles de las im√°genes pre-procesadas (escaladas a 64x64 y aplanadas), permitiendo una soluci√≥n eficiente y con alta interpretabilidad.

### üéØ Objetivos Clave

* Establecer un rendimiento inicial ($\approx 71\%$ de precisi√≥n) con un modelo lineal simple.
* Implementar una arquitectura de **persistencia de datos y modelo** en Google Drive para optimizar el tiempo de ejecuci√≥n en entornos *notebook*.

---

## üõ†Ô∏è Stack Tecnol√≥gico y Dependencias

| Tecnolog√≠a | Rol en el Proyecto |
| :--- | :--- |
| **Python 3.x** | Lenguaje de desarrollo. |
| **Scikit-learn** | Implementaci√≥n del modelo `LogisticRegression` y c√°lculo de m√©tricas. |
| **OpenCV (`cv2`)** | Pre-procesamiento de im√°genes (escala de grises, redimensionamiento). |
| **NumPy / Pandas** | Manejo de arrays de p√≠xeles y formateo de resultados. |
| **Joblib** | Serializaci√≥n y persistencia del modelo en Drive. |
| **KaggleHub** | Gesti√≥n de la descarga del dataset inicial. |

---

## üöÄ Gu√≠a de Configuraci√≥n y Ejecuci√≥n

El proyecto est√° optimizado para ser ejecutado en **Google Colab**.

### 1. Preparaci√≥n del Entorno

1.  Abre el c√≥digo fuente completo en una nueva sesi√≥n de Google Colab.
2.  Ejecuta la primera celda para instalar autom√°ticamente las librer√≠as necesarias (`pip install -q`).
3.  El script solicitar√° la **autorizaci√≥n para montar Google Drive**. Este paso es crucial para la persistencia.

### 2. Flujo de Persistencia de Datos

El script sigue una estrategia condicional para optimizar el tiempo:

* **Primera Ejecuci√≥n:**
    1.  Descarga el *dataset* de Kaggle.
    2.  Ejecuta el **Pre-procesamiento** (aplanamiento, normalizaci√≥n).
    3.  Entrena el modelo de Regresi√≥n Log√≠stica.
    4.  Guarda los arrays de datos (`.npz`) y el modelo entrenado (`.pkl`) en una carpeta de Drive.
* **Ejecuciones Posteriores:**
    1.  El script detecta los archivos persistentes.
    2.  Omite la descarga y el entrenamiento.
    3.  **Carga el modelo y los datos en segundos.**

### 3. Inferencia Interactiva

Una vez finalizado el entrenamiento/carga, el script ejecuta un m√≥dulo de prueba que permite:

* Subir una imagen local (Perro o Gato).
* Pre-procesar la imagen de manera id√©ntica a los datos de entrenamiento.
* Mostrar la predicci√≥n del modelo con su **nivel de confianza** (probabilidad).

---

## üìä Resultados de Evaluaci√≥n

Los resultados se obtuvieron al evaluar el modelo entrenado sobre el conjunto de prueba (20% de los datos).

### 1. Matriz de Confusi√≥n (Valores T√≠picos)

| | Predicho Gato (0) | Predicho Perro (1) |
| :--- | :--- | :--- |
| **Real Gato (0)** | $\mathbf{150}$ (Verdaderos Negativos) | $\mathbf{50}$ (Falsos Positivos) |
| **Real Perro (1)** | $\mathbf{66}$ (Falsos Negativos) | $\mathbf{134}$ (Verdaderos Positivos) |

### 2. M√©tricas Detalladas

| M√©trica | Gato (0) | Perro (1) |
| :--- | :--- | :--- |
| **Precision** | $\approx 0.69$ | $\approx 0.73$ |
| **Recall** | $\approx 0.75$ | $\approx 0.67$ |
| **F1-Score** | $\approx 0.72$ | $\approx 0.70$ |
| **Accuracy Global** | \multicolumn{2}{|c|}{$\mathbf{0.7100}$ ($\mathbf{71.00\%}$)} |

### 3. An√°lisis de las Limitaciones

La precisi√≥n del $\sim 71\%$ refleja la limitaci√≥n del modelo:

* **Regresi√≥n Log√≠stica** crea una **frontera de decisi√≥n lineal**.
* Los problemas reales de clasificaci√≥n de im√°genes (variaciones de pose, iluminaci√≥n) son **no lineales**.
* El modelo pierde informaci√≥n espacial cr√≠tica al **aplanar** la imagen a un vector de 4096 p√≠xeles.

---

## ‚è≠Ô∏è Hoja de Ruta y Pr√≥ximos Pasos

Para superar la barrera de rendimiento del modelo lineal, se plantean las siguientes mejoras:

### A. Mejoras en la Arquitectura

* **Migraci√≥n a CNN:** Implementar una **Red Neuronal Convolucional** para aprovechar su capacidad de aprender jerarqu√≠as de caracter√≠sticas (bordes, texturas) directamente de la estructura 2D de la imagen.
* **Transfer Learning:** Utilizar un modelo preentrenado (ej. ResNet, MobileNet) para acelerar el entrenamiento y mejorar la precisi√≥n aprovechando el conocimiento visual previo.

### B. Mejoras en la Ingenier√≠a de Datos

* **Aumento de Datos:** Aplicar transformaciones aleatorias (*Data Augmentation*) como rotaciones y volteos para aumentar el tama√±o efectivo y la diversidad del conjunto de entrenamiento.

---

## üìù Licencia

Este proyecto est√° distribuido bajo la **Licencia MIT**. Consulta el archivo `LICENSE` para m√°s detalles.
